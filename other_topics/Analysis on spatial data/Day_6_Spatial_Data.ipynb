{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021-06-08 Spatial data - Student Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for today\n",
    "**Scientific Goals:**\n",
    "- Be comfortable loading, plotting and manipulating gridded data\n",
    "- Understand how to weight gridded data\n",
    "- Data organization\n",
    "\n",
    "**Coding Skills:**\n",
    "- Use linux commands: wget, unzip, ncdump, cdo gridarea\n",
    "- Be able to quickly plot data directly from xarray\n",
    "- Output NetCDF files\n",
    "- Use masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "**1. Download data:**\n",
    "* 1.1 Download NetCDF file using `wget` (linux)\n",
    "* 1.2 Unzip NetCDF file using `unzip` (linux)\n",
    "* 1.3 Look at the data (linux `ncdump` and `xarray`)\n",
    "* 1.4 Make some basic plots of the data (`xarray` and `cartopy`)\n",
    "\n",
    "**2. Compute regional averages**\n",
    "* 2.1 Subset your data by selecting a month and time range using `xarray`\n",
    "* 2.2 Compute grid area (`cdo`), weight the data and produce a time series plot\n",
    "* 2.3 Save this data to NetCDF\n",
    "\n",
    "**3. Look at the data with a Hovmuller plot**\n",
    "* 3.1 Make a longitude average\n",
    "* 3.2 Compute and plot data across seasons\n",
    "* 3.3 Play around with different color maps and sine weightings (extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and define useful lists\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "\n",
    "month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the data\n",
    "**We'll be using HadCRUT5 which is a gridded observational surface temperature dataset from the Met Office and University of East Anglia. <br>\n",
    "You can find the files you're able to download from [their website](https://www.metoffice.gov.uk/hadobs/hadcrut5/data/current/download.html) along with documentation<br>\n",
    "Below is a comparison between global temperature datasets, of which HadCRUT5 is one**<br>\n",
    "<img src=\"https://www.metoffice.gov.uk/hadobs/hadcrut5/figures/HadCRUT5_figure_7.png\" alt=\"HadCRUT5 time series\" width=\"1000\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 `wget` (Linux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's first have a look where we are, using linux terminal within Jupyter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you want to change your working directory, with Python, use:** <br>\n",
    "`os.chdir(<new/path>)` <br> <br>\n",
    "**Now we will use 'wget', this downloads data from a URL. Use the 'help' flag** `!wget --help` **to print useful information about a Linux command** <br>\n",
    "\n",
    "<span style=\"color:blue\">**Execute the cell below to download the HadCRUT NetCDF file**</span> <br>\n",
    "**If you would like to download the file to a directory other than your current working directory, use the '-P' flag:** <br> \n",
    "`wget <URL> -P </path/to/folder>` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.metoffice.gov.uk/hadobs/hadcrut5/data/current/analysis/HadCRUT.5.0.1.0.analysis.anomalies.ensemble_mean_netcdf.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you'd like to know the size of the file you're downlading (and other info) run:** `wget --spider <URL>` <span style=\"color:blue\"> **Copy a link address on the [HadCRUT5 webite](https://www.metoffice.gov.uk/hadobs/hadcrut5/data/current/download.html) and try this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 `unzip` (Linux)\n",
    "**Now let's check we have unzip installed, if so we should have the version number printed and a list of common commands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> **Let's unzip the file we downloaded (HadCRUT.5.0.1.0.analysis.anomalies.ensemble_mean_netcdf.zip)** </span> <br>\n",
    "**We can check this by runing the linux command** `ls -lh` <br> \n",
    "**This shows a list of files in the current working directory and lists them on a single line with human readable file sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip HadCRUT.5.0.1.0.analysis.anomalies.ensemble_mean_netcdf.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's check we've extracted this file properly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Looking at the data (Python: `xarray`, Linux: `ncdump`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Open the file with**</span> `xarray.open_dataset` **(N.B. we have imported xarray as** `xr`**)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT = xr.open_dataset('HadCRUT.5.0.1.0.analysis.anomalies.ensemble_mean.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's have a look at the dataset,** <span style=\"color:blue\"> **run the variable name. Then click on the two icons at the end of coordinates and data variables, also expand the attributes label** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT #print the xarray dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also use the command line tool** `ncdump` **to quickly look at a NetCDF file without having to use Python.** <br><br>\n",
    "<span style=\"color:blue\">**Try**</span> `ncdump -h <file>` <span style=\"color:blue\">**to look at the file head, and**</span> `ncdump -c <file>` <span style=\"color:blue\">**to look at the coordinates of the file**</span> <br>\n",
    "**For more utilities see [the documentation](https://www.unidata.ucar.edu/software/netcdf/documentation/NUG/netcdf_utilities_guide.html#ncdump_guide) or use** `ncdump --help`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h HadCRUT.5.0.1.0.analysis.anomalies.ensemble_mean.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at the data we find the coordinate 'realization' and the data variable 'realization_bnds'. Let's get rid of these from our data using the following code:** <br>\n",
    "This dataset contains the mean of the 200 ensemble members (which show uncertainties), so the realization data is meaningless and confusing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT = HadCRUT.drop('realization')\n",
    "HadCRUT = HadCRUT.drop('realization_bnds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Plot the data (`xarray` and `cartopy`) \n",
    "<span style=\"color:blue\">**Plot the data (variable** `tas_mean` **) for specific year and month, have a play around with different times, you should find the further back you go the more missing data there is** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Use your knowledge of cartopy from previous days to plot the same figure with coastlines and other features**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute regional averages\n",
    "## 2.1 Subset your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We'll first be looking at January for the period 1950-2020.** <span style=\"color:blue\">**Later on you can see what happens is you change the month and time period** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_ = 1 #select which month you're interested in\n",
    "start_yr = 1940 \n",
    "end_yr   = 2020\n",
    "\n",
    "#now select data for a reduced time period\n",
    "month_HadCRUT = HadCRUT['tas_mean'].sel(time=HadCRUT['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr)))\n",
    "\n",
    "#plot the start and end years to make sure you've got the correct month (look at the title of the plots)\n",
    "month_HadCRUT.sel(time=str(start_yr)).plot()\n",
    "#See what happens if you comment out the next line (it should make a messy figure!)\n",
    "plt.figure() #N.B if you want to make multiple plots in the same cell, make a new matplotlib figure instance.\n",
    "month_HadCRUT.sel(time=str(end_yr)).plot(); #it's much cleaner to use the ; symbol after your last matplotlib command to stop text being printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that the data is complete in the northern hemisphere back to at least 1950 for all grid cells** <br>\n",
    "**Now we'll define 3 regions and plot the average temperature anomalies over the region - without weighting the grid cells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a list of regions\n",
    "region_list = ['arctic', 'ex_trop', 'tropics']\n",
    "\n",
    "#Define a dictionary of latitude min and max for each region\n",
    "lat_lim = {} #initialize a dictionary\n",
    "lat_lim['arctic'] = [66.6,90] #the minimum and maximum latitude for that region\n",
    "lat_lim['ex_trop'] = [23.5,66.6]\n",
    "lat_lim['tropics'] = [-23.5,23.5]\n",
    "\n",
    "#Compte the spatial mean. What is wrong with doing this? We are weighting all the grid cells equally\n",
    "region_sum = {} #initialize a dictionary\n",
    "for region in region_list:\n",
    "    region_sum[region] = month_HadCRUT.sel(latitude=slice(lat_lim[region][0],lat_lim[region][1])).mean('longitude').mean('latitude')\n",
    "\n",
    "    \n",
    "#Plot the data you've made\n",
    "plt.figure(figsize=[14,5]) #initialize a new figure instance of matplotlib\n",
    "\n",
    "for region in region_list:\n",
    "    region_sum[region].plot(label=region) #include the label so the legend can pick it up\n",
    "\n",
    "#plot vertical lines at 1961 and 1990 which are the edges of the averaging period used to calculate the anomalies\n",
    "#N.B. our dataset uses 'datetime64[ns]' times so we can't just plot the line at 1961 and 1990 - those years have to be in a time format\n",
    "plt.axvline(datetime.datetime(1961,1,1), c='r', linestyle='--', label='anomaly window')\n",
    "plt.axvline(np.datetime64('1990-12-31'), c='r', linestyle='--') #Note this takes np.datetime64 and the previous line took a datetime object\n",
    "\n",
    "plt.grid() #plot grid lines\n",
    "plt.axhline(0, c='0.2') #plot the 0 line\n",
    "plt.legend(); #plot the legend, include ';' to stop text being printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Weighting with `cdo gridarea` (Linux)\n",
    "**The problem with doing what we have just done is that each of the grid cells are not weighted equally, especially in the Arctic** <br>\n",
    "**This means that we need to find out the size of each of the grid cells and weight them** <br>\n",
    "**We can do this by using the linux command** `cdo gridarea <infile> <outfile>` **as below. Documentation can be found [here](https://code.mpimet.mpg.de/projects/cdo/embedded/cdo.pdf)** <br><br>\n",
    "*Note you'll get a warning due to the variable `realization`, it's issues like this why we dropped this variable earlier (but we didn't update the netcdf file)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cdo gridarea HadCRUT.5.0.1.0.analysis.anomalies.ensemble_mean.nc HadCRUT_weights.nc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's open up the grid cell area file and plot it, note the colorbar label tells you the units - we could also find this out by using** `ncdump` **or looking at the xarray variables as** `cdo` **provides coordinate labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = xr.open_dataset('HadCRUT_weights.nc')\n",
    "weights['cell_area'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try creating regional averages again, but this time we'll weight each of the regions' grid cells properly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sums = {}\n",
    "for region in region_list: #loop through the 3 regions\n",
    "    \n",
    "    #select the grid cell areas for the latitudes required for that region\n",
    "    weights_lat_slice = weights['cell_area'].sel(latitude=slice(lat_lim[region][0],lat_lim[region][1]))\n",
    "    #normalize this by dividing by the sum of all the grid cell areas in that region\n",
    "    weight_region = weights_lat_slice/weights_lat_slice.sum()\n",
    "    \n",
    "    #now we can multiply the anomaly data (within the correct region) with the weights we just calculated\n",
    "    weighted_grid_cells = month_HadCRUT.sel(latitude=slice(lat_lim[region][0],lat_lim[region][1])) * weight_region\n",
    "    #sum across the latitude and longitude (but not time) to get a 2D aray of temperature anomaly and time\n",
    "    weighted_sums[region] = weighted_grid_cells.sum('latitude').sum('longitude')\n",
    "\n",
    "#plot the data you've made\n",
    "fig = plt.figure(figsize=[12,4]) #initialize a new figure instance of matplotlib\n",
    "\n",
    "for region in region_list: #loop through all 3 regions again\n",
    "    weighted_sums[region].plot(label=region) #include the label so the legend can pick it up\n",
    "\n",
    "plt.grid() #plot grid lines\n",
    "plt.axhline(0, c='0.2') #plot the 0 line\n",
    "plt.legend(); #plot the legend, include ';' to stop text being printed\n",
    "plt.ylabel('Temperature anomaly from 1961-1990 [K]'); #we don't have automatic labels as we have multuplied the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we've labeled the figure above as** `fig` **we can now call this and the plot will appear, this can also be uesful for saving with** `fig.savefig(<file/path.png>)` \n",
    "<span style=\"color:blue\"> **Try plotting this figure again in a new cell, and then saving it** </span> <br> N.B. to save the figure without cutting off any of the axes you may need to invoke `fig.tight_layout()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.tight_layout() #if you don't include this you'll find the 'time' x-axis label is cut off\n",
    "fig.savefig('Regional_T_anomalies_1940_2020_NH.png',dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see what difference that weighting did**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,4]) #initialize a new figure instance of matplotlib\n",
    "\n",
    "#plot the difference weighting makes\n",
    "for region in region_list:\n",
    "    (region_sum[region]-weighted_sums[region]).plot(label=region) #include the label so the legend can pick it up\n",
    "\n",
    "plt.ylabel('Difference [K]')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 save the output data to NetCDF (`xarray`)\n",
    "**Firstly we want to make an xarray dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weighted_data = xr.Dataset(weighted_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weighted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For future use we need to add attributes as below. This allows us to:**\n",
    "- Tell another person or ourselves at a later date what this dataset contains \n",
    "- Make it obvious to oursleves how we made the dataset (source data and what code created it\n",
    "- When the dataset was created, this is especially important if there are multiple similar output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weighted_data.attrs = {'Description' : 'Regional temperature anomalies for the month of {}, for years 1950-2020. Anomalies relative to 1961-1990'.format(month_names[month_-1]),\n",
    "                            'Units' : 'Kelvin',\n",
    "                            'Timestamp' : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                            'Source': 'Data - HadCRUT.5.0.1.0, doi:10.1029/2019JD032361. Analysis - REU_2021-06-08_Spatial_Analysis.ipynb'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always check your file before saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weighted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always make sure you select a useful and unambiguous name for your data, if you're creating multiple files think about how they will be sorted alphabetically**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weighted_data.to_netcdf('HadCRUT5_temp_anoms_{}_{}_{}.nc'.format(start_yr, end_yr, str(month_).zfill(2))) #use zfill so months sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now check your output with ncdump. [See documentation](https://www.unidata.ucar.edu/software/netcdf/documentation/NUG/netcdf_utilities_guide.html#ncdump_guide)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h  HadCRUT5_temp_anoms_1950_2020_01.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Make a Hovmöller diagram (`xarray` and `cartopy`)\n",
    "## 3.1 Make a longitude average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we'll be using the full dataset again and take the mean across latitude to get 2D data (time, latitude)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT_lon_av = HadCRUT['tas_mean'].mean('longitude', skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT_lon_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT_lon_av.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can get latitude on the y axis to improve readabilit by transposing the data. Making these plot manually in matplotlib takes a lot more work than with xarray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT_lon_av.transpose().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Compute and plot data across seasons\n",
    "**Now let's just select winter (DJF).** <span style=\"color:blue\">**Have a go with the other seasons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT_season_lon_av = HadCRUT_lon_av.groupby('time.season').mean('time')\n",
    "HadCRUT_season_lon_av.sel(season='DJF').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now instead of making a mean across the time dimension, we want to look at the time and latitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT_DJF_lon_av = HadCRUT_lon_av.sel(time=HadCRUT_lon_av['time.season']=='DJF')\n",
    "HadCRUT_DJF_lon_av.transpose().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Play around with the Hovmöller diagram\n",
    "<span style=\"color:red\">**Take a look at the [colormaps](https://matplotlib.org/stable/tutorials/colors/colormaps.html) matplotlib offers, try a few out for yourself while also making any improvements to the figure** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Extension: weight the latitude y-axis by the sine of latitue to be more representative of the size of the grid cells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
