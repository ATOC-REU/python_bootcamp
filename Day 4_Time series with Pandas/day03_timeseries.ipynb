{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"day03_timeseries.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"RsmNxsNuueIl"},"source":["# Day 2 - Timeseries\n","\n","Today, we will practice manipulating timeseries data. We will use lidar measurements of wind speeds as our toy dataset. These measurements were gathered off the East coast in an area where companies are planning to build wind turbines. We will use these measurements to answer questions like \"what month has the strongest average winds\" and \"how often are winds so weak that they don't spin the turbine\"."]},{"cell_type":"code","metadata":{"id":"bXur6asVueJH"},"source":["### Import libraries\n","from datetime import datetime  # for some datetime manipulations\n","import numpy as np # for data storage and math\n","import pandas as pd # for data storage and timeseries math\n","import matplotlib.pyplot as plt # for plotting"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X9ZCLGqBueJS"},"source":["# Read in data\n","Our lidar measurements are saved as `.csv`'s, which stands for Comma Separated Values. You can think of `.csv` files as spreadsheets where data within a row is seperated with a comma. You can double click on `lidar_winds.csv` in the sidebar and glimpse the data. Tabular data shows up all the time in the geosciences, and one place it is especially common is observational timeseries.\n","\n","`pandas` is a library that is specifically designed to read and analyze tabular data. We will start off by reading our toy dataset of lidar winds into a `pandas` DataFrame."]},{"cell_type":"code","metadata":{"id":"SJ4B1pdBueJT"},"source":["### Read tabluar data into a pandas DataFrame\n","df = pd.read_csv(\"lidar_winds.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uu3YD-saueJU"},"source":["We can get a quick idea of what data inside our DataFrame looks like by looking at the first 5 rows with the `.head()` command."]},{"cell_type":"code","metadata":{"id":"jncIGCB9ueJV"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n0VFmzxgueJX"},"source":["and you can look at the end of the DataFram with the `.tail()` command."]},{"cell_type":"code","metadata":{"id":"ecDJkcPtueJZ"},"source":["df.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XzG-oQUXueJb"},"source":["`df` has 11 **columns**. One has timestamps of wind speed measurements, and the rest are wind speed measurements at heights between 18 m and 198 m above the surface. We can isolate just one column of the DataFrame by using `df[\"wspd18\"]`, for example"]},{"cell_type":"code","metadata":{"id":"4Zlpgb_lueJc"},"source":["df['wspd18m']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d6mrlgLJueJd"},"source":["or looking at timestamp values, we run"]},{"cell_type":"code","metadata":{"id":"e9x0FgOeueJe"},"source":["df['timestamp']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"drcKctCyueJe"},"source":["# Preprocessing\n","\n","Before doing any sort of analysis (for example, calculating things like average wind speeds), you often need to preprocess data. `pandas` is very powerful at doing timeseries analysis, but in order to do timeseries analysis, we must reformat the data in a way that is friendly to timeseries analysis. We are going to do two things: reformat the data and change the index.\n","\n","The last row of the above outputs tells us that the data in `wspd18m` is `float64` (a decimal number) and the data in `timestamp` is `object` (which usually means a string). We need to tell `pandas` that the `timestamp` column actually contains timestamps, not just any old regular strings. To do that, we will run the following line"]},{"cell_type":"code","metadata":{"id":"bJNknJhrueJf"},"source":["pd.to_datetime(df['timestamp'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiAtayYlueJg"},"source":["You can now see that the `dtype` in the last line is now `datetime64`. In `pd.to_datetime()`, `pandas` reads though all the data and guessts its format. If you know the format ahead of time, you can specify the format and the data conversion will run quicker. For example, the conversion for the above code would read `pd.to_datetime(df['timestamp'], format='%m-%d-%Y %H:%M')`. [More on conversion codes here.](https://strftime.org/)"]},{"cell_type":"markdown","metadata":{"id":"0rWjiafMueJh"},"source":["### Common pitfall\n","Above, we ran a line of code that converted the `object` format data to `datetime64` formatted data. So, if we rerun `df['timestamp']`, we should see that our data is now `datetime64` data, right?"]},{"cell_type":"code","metadata":{"id":"nSL2md_0ueJh"},"source":["df['timestamp']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i7ON_s8kueJi"},"source":["But in actuality, it's still the `object` datatype. What gives? \n","\n","In `pandas`, **you often need to explicitly state that you want to replace the data in your DataFrame**. In order to replace the data in `timestamp`, run"]},{"cell_type":"code","metadata":{"id":"BnPukEGZueJi"},"source":["df['timestamp'] = pd.to_datetime(df['timestamp'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yF8ejKhpueJj"},"source":["Now, when we look at the data in the `timestamp` column, we see that it is indeed `datetime64`."]},{"cell_type":"code","metadata":{"id":"RqO4mQjYueJj"},"source":["df['timestamp']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PfXTQMwqueJj"},"source":["Now that `pandas` knows that we are working with timeseries data, we need to replace the index with these timestamps. In the above code outputs, you see the numbers `0, 1, 2, ...` to the left of all the data, one for every row. This is the **index**. When reading in data via `pd.read_csv()`, we didn't specify the value of the index, so `pandas` set the value of the index to its default value of `0, 1, 2, ...`. We want to replace this default index with the timeseries index. To do this, run `df = df.set_index(\"<column name>\")`."]},{"cell_type":"code","metadata":{"id":"vKEG4lhfueJk"},"source":["df = df.set_index('timestamp')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TdRZrIcpueJk"},"source":["After running this command, we are done preprocessing. You can output the value of `df` and verify that it looks slightly different now than when we started."]},{"cell_type":"code","metadata":{"id":"lWwtu1jYueJl"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bps-RQSwueJl"},"source":["### By the way: selecting data by row\n","We earlier isolated data by column. We can also isolate data by row. There are two ways to do this, by \"position\" and by \"row value\". If you want to access the data in the 3rd row by \"position\", run `df.iloc[2]` (remember Python's zero-indexing). If you want to access data by \"value\", run `df.loc[datetime(2019, 8, 12, 0, 20)]`. We need to be verbose and state `datetime(2019, 8, 12, 0, 20)` because our data is the `datetime64` data type."]},{"cell_type":"markdown","metadata":{"id":"bcWaqZvVueJo"},"source":["# Processing the data\n","\n","Now that our data is nicely formatted, we can begin to ask questions. For example, what is the average wind speed at every height? To get the average wind speed across all timesteps, run `df.mean()`."]},{"cell_type":"code","metadata":{"id":"m_0QDsKZueJo"},"source":["df.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v6D_hFOpueJu"},"source":["Instead of selecting all timestamps, we can also subselect data by characteristics. For example, we can subselect all data in September. Note, this grabs data in *both* September 2019 *and* September 2020."]},{"cell_type":"code","metadata":{"id":"-oUcb_JYueJv"},"source":["df[df.index.month == 9]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o4QXHmfDueJw"},"source":["You can also grab data from *only* September 2020."]},{"cell_type":"code","metadata":{"id":"9aK9jhvAueJw"},"source":["df[(df.index.month == 9) & (df.index.year == 2020)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0EQpZod6ueJx"},"source":["We can find the average wind speeds in September 2020 by running `.mean()` on the data that we subselect."]},{"cell_type":"code","metadata":{"id":"T88mybtbueJx"},"source":["df[(df.index.month == 9) & (df.index.year == 2020)].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EOLPYrnIueJy"},"source":["### Visualizing the data\n","\n","So far, we have been looking at average wind speed behavior. How do winds behave throughout time? Let's plot 138 m winds."]},{"cell_type":"code","metadata":{"id":"kVabKFGBueJy"},"source":["fig, ax = plt.subplots(1, 1, figsize=(8,3))\n","\n","ax.plot(df.index, df['wspd138m'])\n","\n","ax.set_ylabel(\"Wind Speed [m/s]\", fontsize=12)\n","ax.set_xlabel(\"Date\", fontsize=12)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tvf4m77HueJz"},"source":["We can see that instantaneous winds can be as strong as 30 m/s or as weak as 0 m/s. Let's smooth this time series by averaging winds every week. "]},{"cell_type":"code","metadata":{"id":"UVBb9cSIueJz"},"source":["weekly_winds = df.resample(\"W\").mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4sEwmdhAueJ0"},"source":["fig, ax = plt.subplots(1, 1, figsize=(8,3))\n","\n","ax.plot(df.index, df['wspd138m'])\n","ax.plot(weekly_winds.index, weekly_winds['wspd138m'], color='orange')\n","\n","ax.set_ylabel(\"Wind Speed [m/s]\", fontsize=12)\n","ax.set_xlabel(\"Date\", fontsize=12)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PFLtRuDaueJ3"},"source":["# Challenge: Compare data from lidar and a nearby buoy\n","The lidar is located at 39.9695, -72.160. We can grab measurements from a meteorological buoy, courtesy of [NOAA National Data Buoy Center](https://www.ndbc.noaa.gov/). [Buoy 44025](https://www.ndbc.noaa.gov/station_history.php?station=44025) is at 40.251, -73.164. \n","\n","Column units:\n","* WDIR: degT\n","* WSPD: m/s\n","* GST: m/s\n","* WHVT: m\n","* DPD: sec\n","* APD: sec\n","* MWD: degT\n","* PRES: hPa\n","* ATMP: degC\n","* WTMP: degC\n","* DEWP: degC\n","* VIS: mi\n","* TIDE: ft"]},{"cell_type":"code","metadata":{"id":"Ak-x3BgfueJ4"},"source":["df_buoy = pd.read_csv('buoy_data.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LC-gXYdAueJ4"},"source":["df_buoy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_DGYNhXhueJ7"},"source":[""],"execution_count":null,"outputs":[]}]}